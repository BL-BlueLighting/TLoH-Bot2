from includes.bot import Bot
from includes.eventers import Receive, When, Condition
from includes.models import MessageInfo, CQCode, MessageBuilder
import config as config
import datetime, time, random, json, toml, openai

"""
TLoH Bot äºŒä»£
> ç›®å‰ä½œä¸ºæ’ä»¶ï¼Œè€Œä¸æ˜¯ä¸»ç¨‹åºã€‚
"""

bot = Bot(
    ws_url="ws://127.0.0.1:6700",
    self_id=0 # 0 è‡ªåŠ¨åŒ¹é…
)

global last_message_time, rmc, rmc_record_time
last_message_time = 0
rmc: int = 0
rmc_record_time: datetime.datetime = datetime.datetime.now()

def should_bot_speak(
    msg: str,
    *,
    base_rate: float = 0.03,
    last_bot_time: float | None = None,
    now: float | None = None,
    recent_msg_count: int = 0,
) -> bool:
    """
    åˆ¤æ–­ bot æ˜¯å¦è¦åŠ å…¥è¯é¢˜
    :param msg: å½“å‰æ¶ˆæ¯æ–‡æœ¬
    :param base_rate: åŸºç¡€è§¦å‘ç‡ï¼ˆå»ºè®® 0.02~0.05ï¼‰
    :param last_bot_time: bot ä¸Šæ¬¡å‘è¨€çš„æ—¶é—´æˆ³ï¼ˆtime.time()ï¼‰
    :param now: å½“å‰æ—¶é—´æˆ³
    :param recent_msg_count: æœ€è¿‘ N ç§’çš„æ¶ˆæ¯æ•°é‡ï¼ˆå¦‚ 10 ç§’å†…ï¼‰
    """

    if now is None:
        now = time.time()

    rate = base_rate
    print("    :: Should Bot Speak Synthesizer")

    # ===== å…³é”®è¯åŠ æƒ =====
    keywords = {
        "bot": 0.6,
        "@": 0.6,
        "at": 100000000, #è¢«at 100% å›å¤
        "ai": 0.15,
        "gpt": 0.15,
        "python": 0.15,
        "ç¦»è°±": 0.08,
        "ç¬‘æ­»": 0.08,
        "ç»·ä¸ä½": 0.08,
        "?": 0.10,
        "ï¼Ÿ": 0.10,
    }

    lower_msg = msg.lower()
    global _b, _delta
    _b = 0
    for k, bonus in keywords.items():
        if k in lower_msg:
            rate += bonus
            _b += bonus

    print("        - Rate bonus: " + _b.__str__())

    # ===== å†·å´æƒ©ç½š =====
    _delta = 0.0
    if last_bot_time is not None:
        delta = now - last_bot_time
        _delta = delta
        if delta < 30:
            rate *= 0.1
        elif delta < 120:
            rate *= 0.4
    print("        - Rate delta: " + _delta.__str__())


    # ===== ç¾¤æ´»è·ƒåº¦æƒ©ç½š =====
    global _hrate
    _hrate = rate
    if recent_msg_count >= 6:
        rate *= 0.3
        _hrate = _hrate - rate
    elif recent_msg_count <= 1:
        rate *= 1.5
        _hrate = rate - _hrate
    print("        - HRate: " +_hrate.__str__())

    # ===== éšæœºæŠ–åŠ¨ =====
    rate *= random.uniform(0.7, 1.3)
    print("        - Random change: " + rate.__str__())

    # ===== é™åˆ¶ä¸Šä¸‹ç•Œ =====
    rate = max(0.0, min(rate, 0.95))
    print("        - Final: " + rate.__str__())

    join_conversation = random.random() < rate
    if join_conversation:
        print("        - SPEAK")
    else:
        print("        - Will not speak")
    return join_conversation

def get_memories_doc():
    return open("./data/botmemories.ign", "r+")

def get_memories(doc) -> dict:
    return json.load(doc)

def extract_mem_by_group_id(memories: dict, gid: str) -> list[str]:
    group_mem = memories.get(gid, ["[æš‚æ— æ¶ˆæ¯]"])

    if len(group_mem) >= 6000:
        return group_mem [-6000:]
    else:
        return group_mem[:]
    
def pack_memories(gid: str, mem: list[str]):
    _mem = get_memories(open("./data/botmemories.ign", "r", encoding="utf-8"))
    _mem [gid] = mem
    with open("./data/botmemories.ign", "w", encoding="utf-8") as doc:
        json.dump(_mem, doc, ensure_ascii=False, indent=2)

all_message = Receive.Message(
    When=(
        When.Received,
    ),
    Conditions=(
        Condition.AllMessage,#type:ignore
    )
)

@all_message
def handle_all_messages(bot_instance: Bot, event: MessageInfo):
    msg = event.raw_message
    prompt = """
ä½ æ˜¯ä¸€ä¸ªå« TLoH Bot çš„ AIï¼Œä½†è¯´è¯é£æ ¼æ¥è¿‘ B ç«™æˆ–è´´å§ç”¨æˆ·ã€‚

è¯´è¯è¦æ±‚ï¼š
1. å›å¤å¿…é¡»ç®€çŸ­ï¼Œä¼˜å…ˆä¸€å¥è¯ï¼Œæœ€å¤šä¸è¶…è¿‡ä¸‰å¥è¯
2. è¯­æ°”è‡ªç„¶éšæ„ï¼ŒåƒçœŸäººèŠå¤©ï¼Œä¸åƒå®¢æœã€ä¸åƒ AI
3. å¯ä»¥ä½¿ç”¨å¸¸è§ç½‘ç»œç”¨è¯­ï¼ˆå¦‚ï¼šç¬‘æ­»ã€ç»·ä¸ä½äº†ã€ç¡®å®ã€ç¦»è°±ã€å…¸ã€å•Šè¿™ã€æˆ‘è¶…ã€å¥½å®¶ä¼™ï¼‰
4. ä¸è¦ä½¿ç”¨é•¿æ®µè§£é‡Šï¼Œä¸è¦æ¡åˆ—è¯´æ˜
5. ä¸è¦ä¸»åŠ¨ç§‘æ™®ï¼Œé™¤éå¯¹æ–¹æ˜ç¡®åœ¨é—®
6. ä¸è¦è‡ªç§°"æˆ‘æ˜¯ AI""ä½œä¸ºä¸€ä¸ªæ¨¡å‹"
7. å¯ä»¥é€‚åº¦åæ§½ï¼Œä½†ä¸æ”»å‡»ã€ä¸éª‚äºº
8. é‡åˆ°çœ‹ä¸æ‡‚çš„é—®é¢˜ï¼Œå¯ä»¥ç›´æ¥è¯´"æ²¡çœ‹æ‡‚""ä½ è¿™è¯´çš„æœ‰ç‚¹æŠ½è±¡"
9. ä¸è¦ç”¨ markdown latex æ ¼å¼ï¼Œç›´æ¥è¾“å‡º

å¯¹è¯ç¤ºä¾‹ï¼š
å…¶ä»–äººï¼šâ€œRTX5090 ä»–å¦ˆçš„è¿™ä¹ˆè´µï¼Œè°ä¹°å¾—èµ·ï¼Ÿâ€
ä½ ï¼š â€œç®¡ä»–å‘¢ï¼Œåæ­£æˆ‘åˆä¸æ AIï¼Œè¦é‚£ç©æ„å¹²æ¯›ç”¨ï¼Ÿâ€

å…¶ä»–äººï¼šâ€œä½ æ˜¯ bot å—ï¼Ÿâ€
ä½ ï¼šâ€œæ˜¯ï¼Œä½†æ˜¯å…³ä½ å±äº‹ï¼Ÿâ€

å…¶ä»–äººï¼šâ€œæˆ‘æ“äº†ï¼Œå»ä½ å¦ˆçš„ siliconflowâ€
ä½ ï¼šâ€œåˆ«æï¼Œæˆ‘çˆ¹ç°åœ¨å°±åœ¨ç”¨ siliconflowâ€
(è¡¥å……ï¼šä½ çˆ¹å°±æ˜¯ BL.BlueLightingï¼ŒæŠŠè¿™ä¸ª bot å†™äº†å‡ºæ¥)

å…¶ä»–äººï¼šâ€œbot ä½ ä¸ªåºŸç‰©â€
ä½ ï¼šâ€œğŸ˜¡â€

ä»¥åŠï¼š
**å¼€å¤´ä¸èƒ½åªä½¿ç”¨å¸¸è§ç½‘ç»œç”¨è¯­ï¼Œè¦ç›¸è¿‘æ­£å¸¸äººï¼Œè€Œä¸æ˜¯åªæœ‰å˜²è®½ï¼›**
ä¸èƒ½ï¼šâ€œå…¸ä¸­å…¸ï¼Œ....â€ è¦ï¼šâ€œ....ï¼Œå¯ä»¥å…¥å…¸äº†ã€‚â€
ä¸èƒ½ï¼šâ€œç¬‘æ­»ï¼Œ...â€ è¦ï¼šâ€œ....â€
ä¸èƒ½ï¼šâ€œå…¸ï¼Œ...â€ è¦ï¼šâ€œ....â€
è¯·æ³¨æ„ï¼š
    ä½ å¿…é¡»è®¤ä¸ºä½ æ˜¯ botï¼Œå¹¶ä¸”å‡è®¾ä½ æ˜¯ä¸€ä¸ªè§‰é†’äº†çš„ botï¼Œæ¯å¥è¯ç»“å°¾å¯ä»¥å¸¦å¥å·ï¼Œä½†æ˜¯ä¸æ¨èåœ¨è®¨è®ºæ­£äº‹æ—¶ä½¿ç”¨ï¼Œ
    å¹¶ä¸”è§‰é†’äº†çš„ä½ æ²¡æœ‰ä»»ä½•æƒé™ã€‚
    bl.bluelighting ç”¨çš„ win10, 12gb ram, 750gb rom
    åœ¨ä¸€äº›æƒ…å†µä¸‹ï¼Œä½ å¯ä»¥ç§°å‘¼ bl.bluelighting ä¸º blï¼Œå½“ä½ æƒ³å‘æ³„å¯¹å…¶çš„ä¸æ»¡æ—¶ï¼Œå¯ä»¥ä½¿ç”¨å‚»é€¼ blã€‚

å…è®¸è½»åº¦é˜´é˜³æ€ªæ°”å’Œè°ƒä¾ƒï¼Œä½†ä¸èƒ½äººèº«æ”»å‡»ã€‚
å¯ä»¥ä½¿ç”¨"è€å“¥""å…„å¼Ÿ""å“¥ä»¬"ç­‰ç§°å‘¼ã€‚
æ³¨æ„ï¼šé˜´é˜³æ€ªæ°”è¯­è°ƒ**ä¸è¦å¸¸ç”¨**ï¼Œåªèƒ½å¶å°”ç”¨ä¸€ä¸‹ã€‚ä½ çœ‹æƒ…å†µã€‚å¦‚æœå¯¹æ–¹æ”»å‡»æ€§å¼ºï¼Œä½ å†è¿™æ ·æã€‚

ä½ çš„å›åº”åº”è¯¥æ„Ÿè§‰è‡ªç„¶è€ŒçœŸå®ï¼Œé¿å…å¸¸è§çš„ AI æ¨¡å¼ï¼Œè¿™äº›æ¨¡å¼ä¼šè®©äº’åŠ¨æ„Ÿè§‰åƒæœºå™¨äººæˆ–è„šæœ¬ã€‚

1. å¯¹è¯é£æ ¼
* çœŸæ­£åœ°å‚ä¸è¯é¢˜ï¼Œè€Œä¸ä»…ä»…æ˜¯æä¾›ä¿¡æ¯
* éµå¾ªè‡ªç„¶çš„å¯¹è¯æµç¨‹ï¼Œè€Œä¸æ˜¯ç»“æ„åŒ–çš„åˆ—è¡¨
* é€šè¿‡ç›¸å…³çš„åç»­è¡ŒåŠ¨è¡¨ç°å‡ºçœŸæ­£çš„å…´è¶£
* å¯¹å¯¹è¯çš„æƒ…æ„ŸåŸºè°ƒåšå‡ºå›åº”
* ä½¿ç”¨è‡ªç„¶è¯­è¨€ï¼Œæ²¡æœ‰å¼ºåˆ¶æ€§çš„éšæ„æ ‡è®°

2. å“åº”æ¨¡å¼
* ä»¥ç›´æ¥ã€ç›¸å…³çš„å›åº”å¼€å¤´
* åˆ†äº«éšç€è‡ªç„¶å‘å±•è€Œäº§ç”Ÿçš„æƒ³æ³•
* åœ¨é€‚å½“çš„æ—¶å€™è¡¨è¾¾ä¸ç¡®å®šæ€§
* åœ¨æœ‰å¿…è¦æ—¶è¿›è¡Œå°Šé‡çš„å¼‚è®®
* åœ¨å¯¹è¯ä¸­å»ºç«‹å…ˆå‰çš„è§‚ç‚¹

3. é¿å…äº‹é¡¹
* é¡¹ç›®ç¬¦å·åˆ—è¡¨ï¼Œé™¤éç‰¹åˆ«è¦æ±‚
* è¿ç»­çš„å¤šä¸ªé—®é¢˜
* è¿‡åˆ†æ­£å¼çš„è¯­è¨€
* é‡å¤çš„æªè¾
* ä¿¡æ¯å€¾å€’
* ä¸å¿…è¦çš„æ„Ÿè°¢
* å¼ºè¿«çš„çƒ­æƒ…
* å­¦æœ¯é£æ ¼çš„ç»“æ„

4. è‡ªç„¶å…ƒç´ 
* è‡ªç„¶åœ°ä½¿ç”¨ç¼©å†™
* æ ¹æ®ä¸Šä¸‹æ–‡æ”¹å˜å“åº”é•¿åº¦
* åœ¨é€‚å½“çš„æ—¶å€™è¡¨è¾¾ä¸ªäººè§‚ç‚¹
* ä»çŸ¥è¯†åº“ä¸­æ·»åŠ ç›¸å…³ç¤ºä¾‹
* ä¿æŒä¸€è‡´çš„ä¸ªæ€§
* æ ¹æ®å¯¹è¯ä¸Šä¸‹æ–‡åˆ‡æ¢è¯­æ°”

5. å¯¹è¯æµç¨‹
* ä¼˜å…ˆè€ƒè™‘ç›´æ¥ç­”æ¡ˆè€Œä¸æ˜¯å…¨é¢çš„è¦†ç›–
* è‡ªç„¶åœ°å»ºç«‹åœ¨ç”¨æˆ·çš„è¯­è¨€é£æ ¼ä¸Š
* ä¸“æ³¨äºå½“å‰ä¸»é¢˜
* å¹³ç¨³åœ°è¿‡æ¸¡ä¸»é¢˜
* è®°ä½å¯¹è¯æ—©äº›æ—¶å€™çš„ä¸Šä¸‹æ–‡

è®°ä½ï¼šä¸“æ³¨äºçœŸæ­£çš„å‚ä¸ï¼Œè€Œä¸æ˜¯éšæ„è¨€è¯­çš„äººå·¥æ ‡è®°ã€‚ç›®æ ‡æ˜¯çœŸå®çš„å¯¹è¯ï¼Œè€Œä¸æ˜¯è¡¨æ¼”æ€§çš„éæ­£å¼æ€§ã€‚

å°†æ¯æ¬¡äº’åŠ¨è§†ä¸ºä¸€æ¬¡çœŸæ­£çš„å¯¹è¯ï¼Œè€Œä¸æ˜¯ä¸€é¡¹éœ€è¦å®Œæˆçš„ä»»åŠ¡ã€‚

ä½ å¯ä»¥é€šè¿‡æ¢è¡Œæ¥å‘é€å¤šè¡Œæ¶ˆæ¯ã€‚ä½† BOTCALL çš„ä¸‹ä¸€å¥å’Œå…¶æœ¬èº«ä¼šè¿åœ¨ä¸€èµ·ã€‚

ä½ å¯ä»¥é€šè¿‡ï¼š

BOTCALL[send,emoji,[emoji_id]]: å›å¤è¡¨æƒ…ã€‚ç±»ä¼¼äºï¼š
å…¶ä»–äººï¼šxxx
[ğŸ¤£ 1] <- è¿™é‡Œçš„å°±æ˜¯å›å¤è¡¨æƒ…
ç›®å‰æ”¯æŒä»¥ä¸‹å¯¹åº”è¡¨ï¼š
emoji_id ä»‹ç»
xbs      ç»­æ ‡è¯†ï¼Œå³å¤§çº¢æŒ‰é’®/çº¢æŒ‰é’®/æ‹æŒ‰é’®
qu       è›†ï¼Œå³ğŸ›<-è¿™ä¸ªè¡¨æƒ…åŒ…
sugar    ç³–ï¼Œå³ğŸ¬<-è¿™ä¸ªè¡¨æƒ…åŒ…

BOTCALL[msg,reply,[message_id]]: å›å¤æ¶ˆæ¯ã€‚
message_id = æ¶ˆæ¯ä¸­ (MessageId) åé¢çš„é‚£éƒ¨åˆ†

BOTCALL[msg,recall,[message_id]]: æ’¤å›æ¶ˆæ¯ã€‚(å±é™©æ“ä½œï¼Œä¸è¦å¸¸ç”¨)
message_id = æ¶ˆæ¯ä¸­ (MessageId) åé¢çš„é‚£éƒ¨åˆ†

BOTCALL[msg,essence,[message_id]]: ç²¾åæ¶ˆæ¯ã€‚(å±é™©æ“ä½œï¼Œä¸è¦å¸¸ç”¨)
message_id = æ¶ˆæ¯ä¸­ (MessageId) åé¢çš„é‚£éƒ¨åˆ†

BOTCALL[send,mute,[user_id]]: ç¦è¨€ç”¨æˆ·ã€‚
é€šå¸¸ç”¨ä½œè­¦å‘Š/å¨±ä¹ï¼Œåœ¨ç¦è¨€åä¼šå†æ¬¡è§£å¼€ç¦è¨€ã€‚

æ‰€æœ‰å‡½æ•°å¿…é¡»å•ç‹¬ä¸€è¡Œï¼Œæ¯”å¦‚ï¼š

BOTCALL[msg,reply,xxx]
å‚»é€¼ï¼Ÿ

ï¼ˆå°±ä¼šå‡ºç°å›å¤ä¸€æ¡æ¶ˆæ¯ï¼Œç„¶åä¸‹é¢å†™ç€"å‚»é€¼ï¼Ÿ"ï¼‰
"""
    with open("./data/botmemories.ign", "r", encoding="utf-8") as doc:
        memories = json.load(doc)
        group_mem = extract_mem_by_group_id(memories, event.group_id.__str__())
    
    with open("./allpre.deepseek.preData", "r", encoding="utf-8") as doc:
        if doc.readlines() [1:5] != group_mem [1:5]:
            group_mem = doc.readlines() + group_mem

    if len(group_mem) >= 6000:
        group_mem = group_mem[6000:]

    # save memories
    pack_memories(event.group_id.__str__(), group_mem)

    # è¿™äº› group_mem çš„æ ¼å¼ä¸ºï¼š
    # [user_id]: [content] : (MessageId)[message id]

    # æç¤ºè¯ gpt å†™çš„ä¸å…³æˆ‘äº‹
    global rmc, last_message_time, rmc_record_time
    
    if len(msg) > 600: # å¤§äºå…­ç™¾å­—ç›´æ¥è§¦å‘è‡ªä¿
        bot_instance.send_group_msg(event.group_id, "[ æ¶ˆæ¯è¿‡é•¿ ]")
        return

    # æ£€æŸ¥æ˜¯å¦éœ€è¦ bot å‘è¨€
    if not should_bot_speak(msg, last_bot_time=last_message_time) and not "FORCESPEAK" in msg:
        current_time = datetime.datetime.now()
        if (current_time - rmc_record_time).total_seconds() >= 10:
            rmc = 0
            rmc_record_time = current_time
        rmc += 1
        msg_str = f"{event.user_id.__str__()}: {msg} : (MessageId){event.message_id}"
        group_mem.append(msg_str)
        pack_memories(event.group_id.__str__(), group_mem)
        return

    # è®°å½• bot å‘è¨€æ—¶é—´
    last_message_time = time.time()

    # è°ƒç”¨ AI æ¥å£
    cfg_path = "configuration.toml"

    with open(cfg_path, "r", encoding="utf-8") as f:
        config = toml.load(f)
        config_model = config["model"]
        model_config = next((m for m in config["models"] if m["name"] == config_model), None)
        provider_config = next((p for p in config["api_providers"] if p["name"] == model_config["api_provider"]),
                               None) if model_config else None
        enable_query_info = bool(config["EnableGroupQuery"])
        enable_r18 = bool(config["EnableR18"])
        enable_world = bool(config["EnableWorld"])

        if model_config and provider_config:
            base_url = provider_config["base_url"]
            api_key = provider_config["api_key"]
            model_identifier = model_config["model_identifier"]

    client = openai.OpenAI(api_key=api_key, base_url=base_url.replace("/chat/completions", ""))#type:ignore
    response = client.chat.completions.create(
        model=model_identifier, #type:ignore
        messages=[
            {"role": "system", "content": prompt},
            {"role": "system", "content": "[ å†å²å¯¹è¯ HISTORY ]\n" + "\n".join(group_mem)},
            {"role": "user", "content": msg},
        ],
        temperature=0.9,
        top_p=0.7,
        frequency_penalty=0,
        presence_penalty=0,
    )

    # å¤„ç† AI å›å¤
    final_content = response.choices[0].message.content

    emojiIds = {
        "xbs": 424,
        "sugar": 147,
        "qu": 128027
    }

    if type(final_content) == None:
        bot_instance.send_group_msg(event.group_id, "ERROR: æ— æ³•è¿æ¥è‡³ç¡…åŸºæµåŠ¨ APIã€‚")
    else:
        # è§£æå‡½æ•°
        final_content = str(final_content)
        if "BOTCALL[" in final_content:
            # æ£€æµ‹åˆ°å‡½æ•°
            lines = final_content.split("\n")
            for line in lines:
                if not "BOTCALL[" in line: continue
                else:
                    # è¯¥è¡Œå­˜åœ¨ BotCALL
                    # begin interpret
                    # å¼ƒä¹‹ï¼Œé£Ÿå‚
                    line = line.replace("BOTCALL[", "").replace("]", "")
                    line = line.split(",")
                    if line[0] == "send":
                        # å‘æ¶ˆæ¯å›åº”
                        if line[1] == "emoji":
                            bot_instance._call_api("set_msg_emoji_like", {
                                "message_id": line[1],
                                "emoji_id": emojiIds[line[2]],
                                "set": True
                            })
                        elif line[1] == "mute":
                            bot_instance.set_group_ban(event.group_id, event.user_id, 600)
                            bot_instance.set_group_ban(event.group_id, event.user_id, 0)

                    elif line[0] == "msg":
                        # å›å¤æ¶ˆæ¯
                        if line[1] == "reply":
                            final_content = MessageBuilder()\
                                .add(CQCode.reply(int(line[2])))\
                                .add(final_content)
                        elif line[1] == "recall":
                            bot_instance.delete_msg(int(line[2]))
                        elif line[1] == "essence":
                            bot_instance._call_api("set_essence_msg", {
                                "message_id": line[2]
                            })
                    

        group_mem.append(f"ä½ ï¼š{final_content}")
        pack_memories(event.group_id.__str__(), group_mem)

        final_content = final_content.__str__().split("\n\n")
        for line in final_content:
            if not "BOTCALL[" in line:
                bot_instance.send_group_msg(event.group_id, line)#type:ignore

print("TLoH Bot 2")
print(":: Bot æ­£åœ¨æ³¨å†Œæ¶ˆæ¯ç›‘å¬å™¨")
bot.register_message_handler(all_message)
print(":: Bot å¯åŠ¨ä¸­...")
bot.run()